Refinements to Your Hierarchical Directive System for AIFP
Your proposed hierarchical directive system is an excellent evolution of AIFP—it keeps the framework lightweight and database-driven while relying on AI's strengths for intent detection and natural reasoning, without needing a custom parser. By starting with high-level checks (e.g., "is this code-related or DB tracking? If not, act normal") and branching deeper only when needed, it achieves your goal: let AI "think" freely like in a standard conversation, but force guidelines for coding (e.g., pure FP, wrappers for libraries) and project management (e.g., DB updates, task alignment with completion_path). This avoids over-constraining AI—directives act as "guardrails" rather than a script, allowing creative problem-solving within boundaries.
Based on the web search results, hierarchical task decomposition in AI systems (e.g., Hierarchical Task Networks or HTN planning) is a mature concept from AI research , where complex goals are broken into subtasks recursively until primitive actions are reached. This aligns perfectly with your if-then hierarchy and task_decomposition directive. For directive-based AI agents, the results emphasize agents that specialize in task management by assigning roles, handling priorities, and automating processes , which supports your tools-as-pointers model and subtask priority handling. I'll refine your ideas with these insights, keeping directives central and AI reasoning intact. No major changes are needed—your system is already well-designed—but I'll suggest tweaks for robustness, especially in intent matching and path identification.
1. Overall Refinement to the Hierarchical Directive System

High-Level Hierarchy: Keep it simple as you described: Start with a root check in the aifp_run directive (code-related? DB tracking update? If no, respond naturally without AIFP enforcement). This preserves AI's "usual" behavior for non-AIFP tasks.

Refinement: Incorporate HTN-inspired recursion  in the workflow JSON—branches can call sub-directives (e.g., "if code, then call directive_fp_code_gen"), allowing parallel or sequential execution. Add a "normal_mode" branch: "if not AIFP-related, then respond as standard AI, but log query in notes table for potential future directive."
Rationale: This prevents directive overload—if a user asks something unrelated (e.g., "Tell me a joke"), AI doesn't force AIFP, but logs it for system improvement. It also enables parallel branches , e.g., code gen + DB update.


For Code-Related Tasks: Your branch (library? Build wrapper; update files? Reference standards; after file, update DB) is spot on. Refine with agentic specialization : Directives can "assign" subtasks to specialized helpers (e.g., wrapper_builder for libraries), running in parallel if MCP allows.

Refinement: Add a "pre-check" in code branches: Query project.db for open tasks/completion_path to see if the request aligns . If not, prompt user: "This seems off the roadmap—confirm or pivot?"


Tools/Directives Link: Your model (tools as pointers/symlinks to directives) is effective for MCP's restrictions. No change needed, but add a "tool_execution_log" in notes table to track tool calls, helping debug if AI strays.

Rationale: This keeps tools minimal (Python pointers) while directives handle the logic, as you intended.


Intent Detection: Rely on AI for this, as you said—it's better than static code. Refine by adding an intent_helper function to aifp_core.db (simple keyword + context matching), which the aifp_run_tool calls to pre-match directives.

Rationale: AI is superior for natural language , but a helper provides consistency without heavy programming (no weights/blacklists needed—just keywords from intent_keywords_json).


User Referral: Keep as fallback in all directives (e.g., "if unresolved, prompt user"). Add to roadblocks_json: "if task not in directives, prompt user: 'This is outside AIFP—proceed normally or define new directive?'"

2. Refinement to task_decomposition Directive for Path Identification
Your refinement is key—task_decomposition breaks complex requests into AIFP-compliant paths, referencing completion_path. It fits HTN planning , where tasks decompose recursively. Refine to include parallel subtasks (e.g., code gen + DB update) and priority handling for subtasks.

Boundaries for New Task vs Subtask:

New Task: If the request is independent, high-level, or pivots the project (e.g., "Add graph algorithms"—new milestone under completion_path). Criteria: Not linked to open tasks, changes project goals (update project version), or requires new theme/flow.
Subtask: If it's a breakdown of an open task (e.g., "Implement add in math_utils.py" under "Setup" path). Criteria: Directly supports an active task/milestone, low-level (e.g., single file/function), no project pivot.
AI Decision Guidance: In directive workflow: "Think: If request modifies completion_path order_index or project goals, new task. Else, subtask. Confidence <0.5? Prompt user: 'Is this a new task or subtask?' Log to notes."


Priority and Interruption Handling: Subtasks take priority as you said. For interruptions: Check open subtasks in tasks table. If present, notify: "Subtask [name] in progress—complete, discard, or resume?" Update status accordingly (e.g., UPDATE tasks SET status = 'paused' WHERE id = ?).
Updated Directive Insert:
sqlINSERT INTO directives (name, description, workflow, md_file_path, roadblocks_json, intent_keywords_json)
VALUES (
    'task_decomposition',
    'Break user tasks into AIFP-compliant paths',
    '{
        "trunk": "parse_task",
        "branches": [
            {"if": "task_high_level", "then": "create_new_task", "details": {"link_to_completion_path": true, "update_project_goals": true}},
            {"if": "task_low_level", "then": "create_subtask", "details": {"priority": "high", "pause_parent_task": true}},
            {"if": "interruption_detected", "then": "handle_subtask_priority", "details": {"notify_user": true, "options": "complete/discard/resume"}},
            {"fallback": "prompt_user", "details": {"log_note": true, "reference_table": "tasks"}}
        ],
        "error_handling": {"on_failure": "prompt user for clarification"}
    }',
    'directives/task_decomposition.md',
    '[{"issue": "task vs subtask ambiguity", "resolution": "Prompt user for boundary clarification, log in notes"}, {"issue": "no matching open task", "resolution": "Create new task, align to completion_path"}]',
    '["decompose task", "break down", "plan steps"]'
);

.md File for Context (directives/task_decomposition.md):
text# AIFP Directive: task_decomposition

## Overview
Breaks user tasks into AIFP-compliant paths, referencing completion_path.

## Purpose
Ensures tasks align with project roadmap, with subtasks taking priority.

## Workflow Guidance
- Step-by-step thinking: Parse task, query open tasks, decompose recursively (HTN-style), map to tasks/subtasks.
- Task vs Subtask Boundaries: New task for independent/pivots; subtask for breakdowns. Prompt user if unclear.
- Roadblocks: If interruption, notify: "Subtask in progress—complete/discard/resume?"

Benefit: AI thinks naturally (step-by-step decomposition) but follows guidelines (align to completion_path, update DB). HTN-inspired recursion makes it scalable for complex projects .

3. Handling Non-AIFP Tasks

Refinement: In aifp_run directive, add a "non_aifp" branch: "if intent not code/db/project, then respond normally, but log in notes table for potential directive addition."

Rationale: This fulfills your "if no, act as normal" check, keeping AI flexible without forcing AIFP on everything.


Benefit: Prevents over-enforcement, letting AI handle casual queries naturally.

4. General System Benefits and Alignment with Your Goal
This refined system lets AI "act as it usually does" (thinking, prompting user for clarification) while forcing guidelines via directive workflows and DB checks. Directives provide structure without rigidity—AI can escalate to .md or user for edge cases, and think creatively within branches. The tools/directives link remains lightweight, and path identification is dynamic via task_decomposition. No heavy parsing needed—AI handles intent naturally, with helpers for support.


1. Tools/Directives Link
Your original model (tools as pointers to directives) is perfect for MCP’s Python-tool restriction. Dropping the tool_execution_log suggestion eliminates unnecessary DB writes, as you noted—hundreds or thousands of prompts per session would make logging impractical and not worth the debugging benefit.

Update: Keep tools as minimal JSON-returning pointers, but update the system prompt to explicitly instruct AI to query aifp_core.db immediately after a tool call, minimizing token usage. Tools return a standardized JSON response (e.g., {"directive_id": "file_write", "action_hint": "Generate code and update DB"}), which AI parses in one pass to fetch the directive workflow.

Rationale: This avoids extra interaction rounds (user > AI > user > AI) by embedding the directive lookup in the AI’s initial response. The system prompt ensures AI doesn’t stray, enforcing guidelines without logging.
System Prompt Update:
textYou are an AI using AIFP. For `aifp run [task]`, parse the input naturally, query aifp_core.db for the matching directive, and execute its workflow. Enforce pure functional-procedural coding (no OOP, immutability by default) and project management (update project.db, align with completion_path). If not AIFP-related, respond normally but log optionally in notes table. For ambiguity or roadblocks, refer to directive’s md_file_path or prompt user.

Tool Code Example (for aifp_run_tool.py):
pythonimport json

def aifp_run_tool(task: str) -> str:
    return json.dumps({"directive_id": "aifp_run", "action_hint": "Parse intent and match to directive"})

AI Behavior: On seeing aifp run, AI calls the tool, gets the JSON, queries aifp_core.db for aifp_run, parses intent, and branches to sub-directives (e.g., file_write). No extra DB writes or rounds.


Benefit: Keeps tools lightweight, avoids costly back-and-forth, and ensures directives drive logic while AI handles intent naturally.

2. Intent Detection and Path Identification
Your decision to rely on AI for intent detection, bypassing static parsers or helpers, is wise—AI’s natural language capabilities (as seen in modern LLMs ) far outperform custom keyword systems without the need for heavy coding. The hierarchical checks ("code? DB tracking? If no, act normal") are effective, and the task_decomposition directive aligns well with HTN planning for breaking tasks into paths.

Update 1: Streamline Intent Detection in aifp_run:

Remove any reliance on helper functions for intent matching. Instead, update the aifp_run directive’s workflow to emphasize AI’s step-by-step reasoning: "Parse input naturally, match to directive index using context and keywords, prompt user if confidence <0.5."
Add a confidence_threshold field to directives table (default 0.5) to guide AI on when to escalate to user prompts or .md files.
Schema Change:
sqlALTER TABLE directives ADD COLUMN confidence_threshold REAL DEFAULT 0.5;

Updated aifp_run Workflow:
json{
    "trunk": "parse_intent",
    "branches": [
        {"if": "code_related", "then": "fp_code_gen", "details": {"check_library_wrapper": true, "enforce_fp_rules": true}},
        {"if": "db_tracking_update", "then": "update_db", "details": {"parse_files": true, "associate_flows": true}},
        {"if": "not_aifp", "then": "respond_normal", "details": {"log_note_optional": true}},
        {"fallback": "prompt_user", "details": {"clarify": "Is this code-related, DB update, or other?"}}
    ],
    "error_handling": {"on_failure": "prompt user for clarification", "retry": "max 2 attempts"}
}

Rationale: AI handles intent in one pass, reducing token costs. The confidence_threshold formalizes when to escalate, avoiding unnecessary prompts.


Update 2: Enhanced task_decomposition for Path Identification:

Keep your task/subtask boundaries and priority handling, but clarify AI decision-making with explicit criteria in the workflow and .md file. Add parallel execution support (e.g., code gen + DB update) if MCP allows, inspired by HTN’s parallel planning .
Task vs Subtask Boundaries:

New Task: Independent, pivots project (changes project table’s goals/version), or requires new completion_path milestone. Example: "Add graph algorithms" → new milestone.
Subtask: Supports an open task, low-level (e.g., single function/file), no pivot. Example: "Implement add in math_utils.py" → subtask under "Setup."
AI Guidance: "Think: Check tasks table for open tasks. If request aligns, update task or create subtask. If independent or pivots goals, create new task. If confidence <0.5, prompt user: 'Is this a new task or subtask?' Log to notes."


Interruption Handling: If a subtask is active and user interrupts with a new request, AI checks tasks table (status='in_progress', is_subtask=1). Notify: "Subtask [name] in progress—complete, discard, or resume?" Update tasks.status (e.g., 'paused', 'discarded').
Updated Directive Insert:
sqlINSERT INTO directives (name, description, workflow, md_file_path, roadblocks_json, intent_keywords_json, confidence_threshold)
VALUES (
    'task_decomposition',
    'Break user tasks into AIFP-compliant paths',
    '{
        "trunk": "review_open_tasks",
        "branches": [
            {"if": "related_to_open_task", "then": "update_if_needed", "details": {"check_alignment": true}},
            {"if": "new_task_needed", "then": "create_new_task", "details": {"link_to_completion_path": true, "update_project_version": true}},
            {"if": "subtask_needed", "then": "create_subtask", "details": {"priority": "high", "pause_parent_task": true}},
            {"if": "interruption_detected", "then": "handle_subtask_priority", "details": {"notify_user": true, "options": "complete/discard/resume"}},
            {"fallback": "prompt_user", "details": {"clarify": "Is this a new task or subtask?"}},
            {"parallel": ["execute_code_gen", "update_db"], "details": {"if_code_and_db": true}}
        ],
        "error_handling": {"on_failure": "prompt user for clarification", "retry": "max 2 attempts"}
    }',
    'directives/task_decomposition.md',
    '[{"issue": "task vs subtask ambiguity", "resolution": "Prompt user for boundary clarification, log in notes"}, {"issue": "no matching open task", "resolution": "Create new task, align to completion_path"}]',
    '["decompose task", "break down", "plan steps"]',
    0.5
);

Updated .md File (directives/task_decomposition.md):
text# AIFP Directive: task_decomposition

## Overview
Breaks user tasks into AIFP-compliant paths, referencing completion_path in project.db.

## Purpose
Ensures tasks align with project roadmap, with subtasks taking priority over parent tasks.

## Workflow Guidance
- Step-by-step: Query tasks table for open tasks (status='in_progress'). If request aligns, update task or create subtask. If independent/pivots, create new task and update project.version. If confidence <0.5, prompt user: 'Is this a new task or subtask?'
- Boundaries: New task if changes goals or adds milestone; subtask if supports open task (e.g., single function). Log to notes for clarity.
- Interruptions: If subtask active, notify: "Subtask [name] in progress—complete, discard, or resume?" Update tasks.status accordingly.
- Parallel: If code and DB update needed, execute both (e.g., file_write and update_db).
- Roadblocks: If misaligned with completion_path, prompt user: "This pivots goals—confirm?"

Rationale: Leverages AI’s reasoning for decomposition, enforces guidelines via workflow, and supports parallel execution for efficiency. Subtask priority and interruption handling align with your latest input.



3. Handling Non-AIFP Tasks
No update needed—your "if no, act normal" check is perfect. The aifp_run directive’s "not_aifp" branch handles this, with optional logging to notes for potential directive additions.

Update: Add explicit guidance in aifp_run.md: "For non-AIFP tasks, respond conversationally but consider if request could extend AIFP (log suggestion in notes)."

Rationale: Encourages AI to think proactively without forcing guidelines, keeping token costs low.



4. Schema Updates

Add confidence_threshold to directives:
sqlALTER TABLE directives ADD COLUMN confidence_threshold REAL DEFAULT 0.5;

Update tasks table to support subtask priority and interruptions:
sqlALTER TABLE tasks ADD COLUMN is_subtask BOOLEAN DEFAULT 0;
ALTER TABLE tasks ADD COLUMN parent_task_id INTEGER; -- FK to tasks.id
ALTER TABLE tasks ADD COLUMN priority TEXT DEFAULT 'normal'; -- high, normal, low


5. Why These Updates Work

No Logging Overhead: Dropping tool_execution_log keeps the DB lean, avoiding writes per prompt.
No Helper for Intent: AI’s natural parsing avoids extra rounds, saving tokens and aligning with MCP’s integration limits.
Task/Subtask Clarity: Explicit boundaries and interruption handling (complete/discard/resume) make path identification robust, per your latest input.
AI Freedom: Directives guide without scripting—AI thinks step-by-step within workflows, escalating to user or .md for edge cases.
Cost-Effective: Single-pass AI responses minimize API usage, critical for your context.

Example Interaction
User: aifp run Create a math library with fast computation.
AI:
textMatched directive: aifp_run (intent: create project)
Sub-directive: init_project
Please provide a project name (e.g., MatrixCalculator).
User: aifp run Set name to MatrixCalculator with purpose 'Pure functional math library' and goals '["Fast computation", "No OOP"]'.
AI:
textMatched directive: init_project
Project initialized in project.db:
- project: MatrixCalculator (id=1, purpose: Pure functional math library, goals: ["Fast computation", "No OOP"])
- completion_path: Setup (order_index=1, project_id=1)
Scaffolded: .aifp-project folder
Run next: aifp run Create math_utils.py with add function --task_id 1
User: aifp run Create math_utils.py with add function --task_id 1
AI:
textMatched directive: task_decomposition (related to open task)
Sub-directive: file_write
FILE: math_utils.py
CONTENT:
# AIFP_METADATA: {"function_names": ["add"], "deps": [], "theme": "math_ops", "flow": "addition_flow", "version": 1, "task_id": 1}
# Project Purpose: Pure functional math library
def add(a: int, b: int) -> int:
    """Pure: Adds two integers."""
    return a + b

AIFP_WRITE_COMPLETE
Run next: aifp run Verify compliance and update DB --task_id 1
User (Interruption): aifp run Add matrix multiplication --task_id 2
AI:
textMatched directive: task_decomposition
Subtask 'add function' in progress for task_id 1. Complete, discard, or resume before starting new task?
These updates refine your system without changing its core, making it leaner and more aligned with your goal. Want to draft another directive (e.g., fp_code_gen) or test this with a sample session?


====================

You’re right: we haven’t yet defined a table named directives_interactions.
However, since we’re now modeling directive-to-directive relationships, cross-dependencies, and escalation hierarchies, it makes perfect sense to add one.
This table’s purpose is to normalize directive relationships so the MCP can:
Quickly resolve what each directive can trigger or depend on
Support dynamic traversal (e.g., find all sub-directives under a given one)
Enable visualization (e.g., building a graph or call tree of directives)
Validate against cycles or invalid cross-level calls
Let’s design it properly.

🧠 Concept
Each relationship (edge) connects:
A source directive (the caller / parent)
A target directive (the callee / dependency / escalation)
A relationship type (what kind of link this is)
This makes the system flexible enough to represent:
Triggers (project_file_write ➜ project_update_db)
Escalations (project_task_decomposition ⤴ project_compliance_check)
Cross-links (project_compliance_check ↔ fp_purity)
Dependencies (project_update_db depends on data from project_file_write)

Example Data
id	source_directive	target_directive	relation_type	description
1	project_init	project_task_decomposition	triggers	Initialization step spawns task setup.
2	project_file_write	project_update_db	triggers	After file write, update DB metadata.
3	project_task_decomposition	project_compliance_check	escalates_to	Complex decisions delegated upward.
4	project_compliance_check	fp_purity	fp_reference	Calls FP directive to verify purity.
5	project_error_handling	project_user_referral	triggers	Fallback to user prompt on failure.
6	project_update_db	project_dependency_sync	triggers	DB sync step triggered post-update.
⚙️ Use Cases for MCP
Use Case	Example Query
Find all sub-directives triggered by a directive	SELECT target_directive_id FROM directives_interactions WHERE source_directive_id = ? AND relation_type = 'triggers';
Trace escalation path upward	SELECT target_directive_id FROM directives_interactions WHERE source_directive_id = ? AND relation_type = 'escalates_to';
List all FP dependencies	SELECT target_directive_id FROM directives_interactions WHERE source_directive_id = ? AND relation_type = 'fp_reference';
Validate level transitions	Use a JOIN with directives.level to ensure no downward recursion (e.g., level 4 ➜ level 1).
Visualize call graph	Export edges as adjacency list for graphviz or internal visualization tools.

🧠 What a “machine-parsable” version means
The current directive interaction matrix you saw in Markdown (project_directive_matrix.md) is written for humans — readable, visual, hierarchical, and annotated.

A machine-parsable version is the same logical data, but encoded in structured JSON (or optionally CSV/SQL), so your MCP server or AI agent can directly query it, populate tables like directives_interactions, and perform reasoning like:
“Which directives does project_task_decomposition trigger?”
“Which directives escalate upward?”
“Which FP directives are referenced by compliance checks?”
“What are all valid paths from project_init to project_archive?”

🧱 JSON Structure (Recommended)
Each object represents one directive, and includes:
The directive’s own metadata
Lists of relationships (triggers, depends_on, escalates_to, etc.)
Optional fp_links and notes

🧩 Example (Excerpt)
[
  {
    "name": "project_init",
    "level": 1,
    "triggers": ["project_task_decomposition", "project_add_path"],
    "depends_on": ["aifp_run"],
    "escalates_to": [],
    "cross_links": [],
    "fp_links": [],
    "notes": "Entry point for new project creation."
  },
  {
    "name": "project_task_decomposition",
    "level": 2,
    "triggers": ["project_add_path", "project_error_handling"],
    "depends_on": ["project_init"],
    "escalates_to": ["project_compliance_check"],
    "cross_links": ["project_add_path"],
    "fp_links": [],
    "notes": "Breaks user goals into structured roadmap units."
  },
  {
    "name": "project_file_write",
    "level": 3,
    "triggers": ["project_update_db", "project_theme_flow_mapping"],
    "depends_on": ["project_add_path"],
    "escalates_to": [],
    "cross_links": [],
    "fp_links": ["fp_purity", "fp_side_effect_detection"],
    "notes": "Bridges code generation and project.db synchronization."
  },
  {
    "name": "project_compliance_check",
    "level": 4,
    "triggers": ["project_completion_check", "project_metrics"],
    "depends_on": ["project_update_db"],
    "escalates_to": ["project_error_handling"],
    "cross_links": [],
    "fp_links": ["fp_purity", "fp_no_oop"],
    "notes": "Ensures AIFP and FP compliance."
  },
  {
    "name": "project_error_handling",
    "level": 4,
    "triggers": ["project_user_referral"],
    "depends_on": ["project_compliance_check", "project_integrity_check"],
    "escalates_to": [],
    "cross_links": [],
    "fp_links": [],
    "notes": "Handles directive-level errors, logs to notes table."
  }
]

⚙️ How the MCP Can Use It
When ingesting directives:
Parse this JSON file.
For each directive, insert a record into directives.
For each array key (triggers, depends_on, etc.), insert relationship rows into directives_interactions.
Optionally, validate level transitions (e.g., Level 3 can escalate only to Level 4).
When reasoning or visualizing:
Treat this JSON as an adjacency list or graph.
It can be transformed to a Graphviz .dot file, or queried directly by name.

🧾 Equivalent SQL Mapping (optional)
You could also express the same relationships directly as table inserts:

INSERT INTO directives_interactions (source_directive_id, target_directive_id, relation_type, description)
VALUES
((SELECT id FROM directives WHERE name='project_init'),
 (SELECT id FROM directives WHERE name='project_task_decomposition'),
 'triggers', 'Initialization triggers task decomposition'),
((SELECT id FROM directives WHERE name='project_compliance_check'),
 (SELECT id FROM directives WHERE name='fp_purity'),
 'fp_reference', 'Ensures functional purity compliance');

🔍 Summary
Format	Purpose	Ideal Consumer
Markdown Matrix	Human-readable hierarchy	Developers, documentation
Machine-Parsable JSON	Structured graph for queries	MCP, AI reasoning, visualizations
SQL Inserts	DB ingestion (one-time or seed data)	Database initialization

✅ In short, the machine-parsable version is your directive relationship graph in JSON, directly convertible into the directives_interactions table or any graph reasoning layer.



Key Features
Capability	Description
Multi-file support	Uses FP_DIRECTIVE_FILES and PROJECT_DIRECTIVE_FILES arrays, easily extendable later
Schema self-healing	Creates missing tables automatically
Smart update logic	Uses ON CONFLICT(name) to upsert
Relationship linking	Auto-populates directives_interactions from project_directive_graph.json
Audit logging	Writes full summary to logs/sync_report.json
Dry-run safety	Set DRY_RUN=True to simulate import
Hash-based diffing (light)	Quickly detects directive changes for update reporting
🧩 Example Output
🔄 Starting AIFP Directive Sync...
📘 Loaded 30 entries from directives-fp-core.json
📘 Loaded 30 entries from directives-fp-aux.json
📘 Loaded 21 entries from directives-project.json
📊 Linking relationships from project_directive_graph.json
✅ Added: 2
🔁 Updated: 79
🔗 Relationships added: 215
📄 Sync report saved to logs/sync_report.json


This gives you a stable foundation:
Your directives live as JSON (editable, version-controlled), and this Python script ensures your database is always in sync — automatically updating categories, relationships, and FP links.