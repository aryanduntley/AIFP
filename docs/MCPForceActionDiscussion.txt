Yeah, I mean, top of the list are obviously going to be, um, the database updates, so we need to keep the project up to date, um, so we need every, every time we have a file, uh, edit, we need to, we need to make sure that the file's in there, uh, we need to make sure that the, the edits are in there, in terms of any new functions and their parameters, um, that are in there. We don't need to, we don't need specific data on why potentially this or that file was changed, we just need a current state of the, uh, entire file structure of the project. That's, that's the primary thing. Um, we could have a, an, you know, a thing about ideas or, or, um, just, uh, project, uh, chat, I don't know, project concepts or something, where we do have, uh, some listings of, uh, of the idea of the project and, and potentially how it evolves, you know, sometimes those ideas change and we need, we need a reference to why they changed and, uh, so we have a new direction for, for AI. But really, those just the last few tables of that would need to be read, so we have a current state idea, uh, available to AI. We really want AI to be able to pick up at any time, any session, right? You start a new session from, from scratch, we can, we can actually put this MCP server anywhere else.with the, with the project data existing, and anywhere else, any other AI at any other time with absolutely no context, it should be able to immediately start an init, start a status, and check what's available, go through the database, through the, through the directives, and know exactly what's available to it, and then go through the project, through the database of the, on the project side, and know exactly what the project's about, exactly what files exist throughout the entire project, at least have reference to them. It doesn't need to have them all in memory, right? So, it would just go through our status, it would go through the completion path, and it will know exactly where we are in that completion path, it will look at the current task that have been, current acute tasks that have been finished, and those that are still pending, and it'll know exactly where to pick up without any other context. We don't need to write it paragraphs and paragraphs explaining context like what I'm doing to you right now. We've talked about this before, but it's a new session, so I have to give you all the baseline of the project idea so that we can continue talking on this, right? It's very inefficient, and it takes up a lot of time.Spot on-your whole design screams 'stateless sessions that just work'. Top directive: on file-save, auto-trigger the update_helper. That function just reads the file, parses new/changed functions (using whatever AST parser fits your language), inserts them into project.functions table-columns like file_id, name, params_json, signature_hash for quick diffs. Done. Same for file-creation: add to project.files table, then fire the update_helper to scan contents. No opinionated logs, no bloat-just immutable facts. Second: AIFP status shortcode-query views like CURRENT_STATE, which joins files, functions, themes, flows, and completion_path into one atomic snapshot. AI reads that, sees 'completed_steps = four out of seven', sees 'next_flow = validate_user_input', and boom-starts exactly where it left off. No preamble, no recap, no hey, remember last time?. And yes, add an ideas table-columns: timestamp, description_json, status (active/archived), linked_flow_id. But keep it tiny: AI only scans the newest five or so. Anything older is history-don't let nostalgia creep in. Honestly? This is how AI agents should work-like a pilot checking instruments, not re-reading the manual every flight.

This one is a bit, um, I'm trying to, I'm trying to figure this one out. So, on the, on the MCP server side, we'll have either one database or several databases that, that work with the MCP. One will be a reference to, um, all the MCP tools, uh, the functions that it's available, like the helper functions for database writes and reads and all that, uh, and so on, but those are relatively simple. It's the directives that I'm trying to, the schema for that that I'm trying to figure out, and, and exactly how we're going to lay this out, uh, very precise. So, um, things like the ideas, right? Things like the, um, uh, only, only, only five, only the last five of the ideas, things like the tasks, say we have tasks, a task table in the, in the project side of the database, or in the project database, right? Um, we need to know, we need to tell it exactly what to read and how to read it, instead of it trying to just scan through everything, figuring out how does, how does this look, what does this look like, um, because it would need that context as well. It would need to know what that database looks like, how it looks, how far back to read, and it kinda has to figure that out every time, but our directives should tell it exactly what that looks like, what those databases look like.and how to read them. So, it should say, okay, on the, on, on, on the project side, um, in order to figure out current task, read, um, read completion, uh, project completion path, find anything not complete, then from there, that, in that, in that table, we'll have references to, uh, we'll say hierarchical, um, tasks or hierarchical project positions, right? And we'll have a reference to those, and it'll say, now read this one, that's a little bit lower, a little more acute, um, read that, find what's not complete, and if there aren't any of the, any of the references to smaller task lists, read that, find what's not complete, and then once we get to the point of where we, where we should be in the project state, um, that is not complete, read the last three or four, you know, tasks prior to that, so we have, uh, uh, um, some context in terms of what we, where we, where we were before the, um, uh, before the not complete thing, so we have some context in the, in terms of where to start from, and, uh, and then exactly very detailed on, on how to navigate the project structure, um, and in order to know your current status and current state and where to begin.and how to begin.Start the directives table with a name-like project_nav-then columns: trigger (what starts it, like 'on_init'), database_ref ('project_db'), read_sequence (a JSON array of steps), depth_limit (say three), context_window (three previous tasks). Example: {steps: [{table: completion_path, query: SELECT FROM completion_path WHERE complete = 0 ORDER BY hierarchy DESC LIMIT 1, extract: current_task_id}, {table: tasks, query: SELECT FROM tasks WHERE id = :current_task_id}, {table: tasks, query: SELECT FROM tasks WHERE hierarchy = :next_level AND parent_id = :current_task_id AND complete = 0 ORDER BY order ASC}], context: pull last three completed siblings, always_limit: true}. That way, on AIFP status, it fires this exact chain-zero guesswork, instant position. Same pattern for file updates: {on_save: {table: project_files, insert_if_new: true, scan_functions: true, update_params: true}}. Keep 'em all in one JSON blob per directive; SQLite handles it fine, and AI just deserializes on read. No loops, no hunting-just follow the arrow.

So for file management, the directive looks like this: on_write-triggered every time a file's edited. First, call helper_update_file(file_path, checksum)-adds or updates in the files table. Then helper_parse_functions(file_path)-scans for signatures, returns list of name-param pairs, then loop: for each, call helper_upsert_function(name, params_json, file_path). Simple, atomic. If the language's Python, you could even point at ast.parse-it's reliable. No need to reinvent it. And if it's a new file, prepend helper_create_entry, which adds it with status unscanned. That chain stays in the directive-no guesswork, no drift. What language are most of your files in?

The project files can be any language. We have no idea. So this isn't just for me. This is, this is a, an MCP server to be used for anybody. The MCP server files themselves will be Python, but the, um, but the project files for, you know, whatever could be any, any, who knows, whatever code, uh, whatever, uh, whatever coding language anyone could potentially be using, or several of them, who knows? That's, that's unknown.Then we'll keep it language-agnostic-don't try to parse source inside the MCP. Instead, just make the directive say: on_write: log the file_path and raw_content into a temp staging table, then call helper_notify_user('updated: file X-add functions manually or run language-specific parser'). Let the user (or their AI, when it knows) handle the parse, because honestly, you can't write one helper that understands Rust, Go, JS, and Haskell. Or-better-add a column parse_tool in files table. When AI detects a language (from extension, or shebang), it runs a tiny wrapper: if .py, helper_pyparse; if .js, helper_jsparse-those live on the project side, not yours. You just give the directive: on_init, scan files, guess language, queue parse via wrapper; on_write, re-queue. You're not baking assumptions-you're baking hooks. Keeps it general, keeps it light. Sound fair?

And also how, also how to account for, um, OOP libraries, cause every codebase is, is gonna be pulling in a bunch of libraries until AI becomes the coding source for everybody and no one's really coding much anymore and all doing it through AI, uh, and all those libraries at, at some point will be, uh, will be functional procedural as well, but for now, we're, we're calling in libraries of, of all sorts that are gonna be OOP-based. So we need to write wrappers around those so that as, as the project continues and it's calling in all these libraries, it can still write functional procedural, um, disregarding the, or at least having, using the wrapper for those, um, for those libraries that are OOP so that we can just use straight functions.Yes-directives like: On import, if library_name in OOP_BLACKLIST (table: oop_libs), auto-generate or load wrapper from /wrappers/ and inject at top: from wrappers import clean_lib; lib = clean_lib.wrap(original_lib). So if it pulls in pandas-boom, wrapper turns df.apply into pure map/reduce calls, no state, no objects. Keep the blacklist simple: just name and suggested_wrap_type (stateless, curryable). And in your AIFP code rule: Never expose OOP state-return pure values, never mutate. You could even have a helper: wrapper_gen(lang, lib)-AI calls that when it hits a new one, spits out a functional shell, stores it in database under 'wrappers' table, next time just reuses. Keeps OOP ghosts out, forces clean flows. No human babysitting-just follow AIFP, wrap what doesn't fit.

It can, it can get confusing for AI in terms of how to proceed. It can, it's gonna wanna kinda just default to what it always does, but we need to kinda force it to the, um, to the, uh, to the AIFP standards, you know, tell it to always code in this way. That's where these shortcodes idea that I, that I was thinking of come into play. So, um, we need to, uh, it creates task lists on its own and sometimes it, it may or may not put, you know, uh, like at the beginning of the task list, conform to AIFP or use these shortcodes. AIFP, um, uh, use functional programming, or functional, uh, procedural AIFP, uh, you know, store data, end of file, and all these things. So it needs a clean, we'll say one clean, uh, directive work path that's very general for its standard coding that can, that has information to branch off in all the various, um, we'll say parameters or directives that, that control how it codes and, and the updates that happen after every code. So maybe one state flow that, uh, shortcode that kind of forces it under those guidelines every time, and we can, so that we can kind of generalize our, our, our shortcodes and not have a bunch of little.little ones telling it, you need to do this, you need to do this when you, this is the way you, um, you, this is the way you code, this is after every code, or after every file update or new file, you have to store in the database, and so on and so forth. Instead of adding these and chaining these shortcodes, we need one very standardized, um, pathway for, for, you know, the typical coding, um, coding procedures, so that it can follow that, and in it, um, it has any kind of tree or branching, um, to other, to other directives within that, and it can follow that very precisely without having to guess.One master shortcode: AIFP run-that's it. Put it front-and-center in every prompt or task list, so it's the default gatekeeper. In the database, AIFP run expands to a fixed chain: 1) Check status, 2) Apply AIFP style (pure functions, no mutables, recursion over loops, wrap OOP), 3) Write code, 4) On save-trigger file_update_helper, 5) Log to completion path, 6) If blocked, queue next task from hierarchy. Just define AIFP run as a single JSON directive with a workflow array-no branching needed unless you stick a switch in there (like if OOP_detected: wrap). AI sees AIFP run and treats it like muscle memory: it doesn't think do I update the DB?, it just runs the script. That way you're not yelling AIFP! AIFP! DB! AIFP! every line-you're just saying AIFP run and done. Clean, non-intrusive, idiot-proof.

Yes, exactly—the JSON goes in the directives table on the MCP server side, stored in a column like workflow or rules as a JSON blob for each directive. Below is a JSON template for the AIFP run shortcode, designed to act as the master directive that enforces your functional procedural coding style, handles file updates, and manages project state without AI guessing or human hand-holding. It’s structured to be precise, language-agnostic, and flexible for any project, with clear steps for coding, updating the database, and checking completion status.
JSON Template for AIFP run Directive

{
  "directive_name": "AIFP run",
  "trigger": "on_task_start",
  "description": "Master directive for AI coding workflow, enforcing AIFP standards, updating project database, and managing task progression.",
  "workflow": [
    {
      "step": 1,
      "action": "check_status",
      "database_ref": "project_db",
      "query": "SELECT task_id, parent_id, hierarchy_level, is_complete FROM completion_path WHERE is_complete = 0 ORDER BY hierarchy_level DESC, task_order ASC LIMIT 1",
      "extract": ["current_task_id", "parent_id", "hierarchy_level"],
      "context_query": "SELECT task_id, description, is_complete FROM completion_path WHERE parent_id = :parent_id AND is_complete = 1 ORDER BY task_order DESC LIMIT 3",
      "purpose": "Get the current incomplete task and up to 3 prior completed tasks for context."
    },
    {
      "step": 2,
      "action": "apply_coding_style",
      "rules": {
        "style": "functional_procedural",
        "constraints": [
          "use_pure_functions",
          "avoid_mutable_state",
          "prefer_recursion_over_loops",
          "wrap_oop_libraries"
        ],
        "oop_check": {
          "table": "oop_libs",
          "query": "SELECT library_name, wrapper_path FROM oop_libs WHERE library_name IN (:detected_libs)",
          "if_found": "CALL helper_load_wrapper(:wrapper_path)",
          "if_not_found": "CALL helper_generate_wrapper(:library_name, :language_guess)"
        }
      },
      "purpose": "Enforce AIFP coding standards; wrap OOP libraries if detected."
    },
    {
      "step": 3,
      "action": "write_code",
      "target": "current_task_id",
      "output": "file_path",
      "purpose": "Generate code for the current task following AIFP rules."
    },
    {
      "step": 4,
      "action": "update_file",
      "trigger": "on_save",
      "database_ref": "project_db",
      "steps": [
        {
          "substep": 1,
          "call": "helper_update_file(:file_path, :checksum)",
          "table": "files",
          "action": "INSERT OR UPDATE file_path, checksum, last_modified"
        },
        {
          "substep": 2,
          "call": "helper_guess_language(:file_path)",
          "if_known": "CALL helper_parse_functions(:file_path, :language)",
          "if_unknown": "INSERT INTO staging (file_path, raw_content, status) VALUES (:file_path, :content, 'unparsed')",
          "table": "functions",
          "action": "INSERT OR UPDATE function_name, params_json, file_id"
        }
      ],
      "purpose": "Update project database with new/changed files and functions."
    },
    {
      "step": 5,
      "action": "log_completion",
      "database_ref": "project_db",
      "query": "UPDATE completion_path SET is_complete = 1, completed_at = CURRENT_TIMESTAMP WHERE task_id = :current_task_id",
      "if_blocked": "SELECT task_id FROM completion_path WHERE parent_id = :parent_id AND is_complete = 0 ORDER BY task_order ASC LIMIT 1",
      "purpose": "Mark task as complete or queue next task if blocked."
    },
    {
      "step": 6,
      "action": "update_ideas",
      "database_ref": "project_db",
      "query": "SELECT description, status FROM ideas WHERE status = 'active' ORDER BY created_at DESC LIMIT 5",
      "if_changed": "INSERT INTO ideas (description, status, linked_task_id) VALUES (:new_idea, 'active', :current_task_id)",
      "purpose": "Keep only the latest 5 active project ideas for context; log new ideas if provided."
    }
  ],
  "error_handling": {
    "on_failure": "CALL helper_log_error(:step, :error_message)",
    "retry": "max 2 attempts",
    "fallback": "queue raw SQL query for manual review"
  },
  "version": "1.0",
  "created_at": "2025-10-05T09:15:00Z"
}

Schema for directives Table
This JSON sits in the directives table, which could look like this in SQLite:

CREATE TABLE directives (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    directive_name TEXT NOT NULL UNIQUE,
    trigger TEXT NOT NULL, -- e.g., 'on_task_start', 'on_save'
    workflow JSON NOT NULL, -- the JSON blob above
    description TEXT,
    version TEXT,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
);

How It Works

Trigger: on_task_start kicks off whenever AI picks up a new task or session (like AIFP run in a prompt).
Workflow Steps:

Check Status: Queries completion_path for the top incomplete task, grabs three prior completed tasks for context. No scanning entire tables-just one tight query.
Apply Coding Style: Enforces AIFP rules (pure functions, no state, recursion). If an OOP library is detected, it checks the oop_libs table and either loads or generates a wrapper.
Write Code: AI generates code for the task, outputs to a file.
Update File: On save, updates files table with path/checksum, guesses language, parses functions (or stages for later if unknown). Uses helpers to stay fast.
Log Completion: Marks task done or queues the next one if blocked.
Update Ideas: Reads the latest five ideas, logs new ones if provided. Keeps context lean.


Error Handling: If something breaks, log it, retry twice, then fall back to a raw SQL queue for review.
Storage: The JSON lives in workflow column, so AI just grabs directive_name = 'AIFP run' and follows the steps. No files, no bloat.

Why This?

No Guesswork: AI knows exactly what to do-step-by-step, no scanning schemas blindly.
Language-Agnostic: Doesn’t assume project file types; delegates parsing to language-specific helpers.
Minimal Human Input: You say AIFP run, and it’s off-no need to repeat project goals or context.
Scalable: Add new directives (like AIFP status) as rows in the same table, same JSON structure.
Stateless: Any AI, any session, anywhere, picks up exactly where it left off by querying the database.