# PROJECT:
remove project ID fields from all but project table. Should only be one project per database. Should enforce this.

project table entry is a singular entry that defines the broader scope of the project and the infrastructure table relates to it directly.

there should be getter and setters for general update project details and update project infrastructure. These are pretty standalone and don't need very munch interconnection. Directives must show when/how to use these tools during changes.

TOOLS
create_project(name, purpose, goals, status, version, user_directives_status(*Can Be Null))
last_known_git_hash and last_git_sync fields initial values populated automatically.
update_project(name(*Can Be Null), purpose(*Can Be Null), goals(*Can Be Null), status(*Can Be Null), version(*Can Be Null), user_directives_status(*Can Be Null))
add_infrastructure(type, value, description)
update_infrastructure(id, type(*Can Be Null), value(*Can Be Null), description(*Can Be Null))

HELPERS is_sub_helper=true
project_update_git_status()
No parameters needed. get's git data to update last_known_git_hash and last_git_sync 

to avoid the repeat update/create timestap function calls for EVERY SINGLE DATABASE INTERACTION, we need to set triggers for these:

CREATE TRIGGER update_timestamp
AFTER UPDATE ON your_table
FOR EACH ROW
BEGIN
   UPDATE your_table
   SET updated_at = CURRENT_TIMESTAMP
   WHERE id = OLD.id;
END;

CREATE TRIGGER set_created_at
BEFORE INSERT ON your_table
FOR EACH ROW
BEGIN
   -- Set created_at to current timestamp if not already provided
   -- If you want the flexibility to optionally set it manually, you can include a check
   -- to use CURRENT_TIMESTAMP only if created_at is NULL.
   UPDATE your_table
   SET created_at = COALESCE(NEW.created_at, CURRENT_TIMESTAMP)
   WHERE rowid = NEW.rowid;
END;

TOOL
blueprint_has_changed() creates checksum of project blueprint, then evaluates against current checksum in db. returns true or false.

There is only one project per database. We should remove all project ID fields from the other tables as we do not need to waste processing by having to account for that field in all of the tables with every update. Either that or default the project ID to 1, which "should" be the actual project ID. But I recommend removing the project id field from all tables as even having them suggests that there could potentially be more than one project per database, which is not the case.

Themes and flows have to do with project categorization and organization.
Themes are more broad categorization of the various parts of the project. Flows are more detailed strings of actions that are related more to code categorization. A theme could have several flows, but a flow could touch on several themese potentially. Checkout could be a theme and (shipping calculation, tax, payment selection type, payment processing, address entry, etc.) could all be flows that touch on checkout. Address entry could potentially also touch on theme User Registration for example.

## files, functions, types. These all have to do with file and code tracking.
should have an add_file tool and set_function tool to quickly and easily update the database after every file change. These will be used the most and should be very streamlined. 

## files
WE SHOULD ADD file_name to files table. After doing so, should we include file name in path?

TOOL
add_file(path, language)
checksum automated with code (created_at automated with trigger)
return_statements should include "verify flows are added, if necessary, for this file in file_flows table"
checks if file actually exists in path, return "file does not exists, cannot add to database" not exists
uses update_file_metadata(id)

delete_file(file_id, note_reason:text, note_severit:string, note_source:string "ai" or "user", note_type: "entry_deletion") must delete all file_flows with file_id. must get all functions id's with file_id. must delete all types with function_id and if exists must delete all types_functions with function_id. must delete all interactions with function_id as source or target. must delete all functions with file_id

HELPER is_sub_helper=true
validate_file_name(file_name, file_id, flow_string) checks if file name contains file ID and returns an object or dict with true or false and with file_name parsed into parts (file_name->name, the file_name->ID, and a subobject with the file_name->flows whether they're id's only or name:id pairs depending on what we dicide is best only one way should be used)
file_name_normalizer(file_name, file_id, flow_string) what this does listed below

I was going to add a header comment for each file, but there are so many different comment types based on language and file extension that I don't want to have to have a bunch of logic to do this. We could return the desired metadata to AI to figure out comment syntax and add the metadata itself, but I really want to keep AI from dealing with EVERYTHING and let code handle things that are very routine and shouldn't require much thinking (I don't want to write the logic). So, for file metadata I think this should happen:

add file:
file table entry id returned, name var available already
calls rename_file(file_id, name) name variable used, same as name var used for add_file. function defined below

   LOGIC::
   rename_file(file_id, new_name)
      if(empty(new_name)){
         return error("there was no name parameter passed or it was an empty string. This parameter must be populated");
      }
      row_data = get_file(file_id) get's file data.

      $new_name_id, $existing_name = row_data->file_name, $existing_name_id, $file_id, $notes;

      flow_ids = get_flows_for_file(file_id)

         IF WE WILL ADD FLOW NAMES:
         flow_names = get_flow_names_by_ids(flow_ids:dict/array)

            with file id, flow name and flow id:
            originalname-ID{file_id}-{flowname_flowid}-{flowname_flowid}.ext
            checkout-ID42-payment_3-login_7-registration_1.json

            OR

            with file id and flow id:
            originalname-ID{file_id}-{3_7_1}.json
            checkout-ID42-3_7_1.json

            Which do you think is best? The flow name is more accessible to AI and people than just a number. We know "what" flow it is. With just a number, we have to call get_flow_name_by_id(flow_id) to get the flow name or get_flow(flow_id) which will return all flow data. So the real question is whether having the name and id allow for fewer database queries as the information is available right in the file name. I don't want the file names to get ridiculously long though. A file shouldn't be related to too many flows though. Not sure about this.

      flow_string = make flow string from above
      
      existing_name_validity = validate_file_name(existing_name, file_id, flow_string);
      new_name_validity = validate_file_name(new_name, file_id, flow_string);
      
      clean up the new name, even if it's correct. Instead of checking, we'll just ensure it's correct.
      $normalized_new_name = file_name_normalizer(new_name_validity->name, file_id, flow_string)

      existing_name_id = existing_name_validity->ID
      new_name_id = new_name_validity->ID

      Note: $existing_name_validity->valid == true assumes that $existing_name_validity->ID is not null. If ID was emtpy or null or None, $existing_name_validity->valid would be false.

      if($existing_name_validity->valid && $existing_name_validity->ID != $file_id){
        $notes = "For some reason the pre-existing file name (${existing_name}) had an incorrect file ID (${existing_name_validity->ID}). The file ID is (${file_id}). The new name has been cleaned and normalized, but this discrepancy is worrisome and should be investigated. This message is from rename_name.";
      }

      get actual file from row_data->path and row_data->name
      if file not exists
      return error("Unable to find file listed in datbase with file id $file_id and path $row_data->path. Please investigate and make sure the file exists.)

      if($existing_name == $normalized_new_name){
         return ("File exist. No changes to name, nothing to change." + $notes);
      }

      get's actual file
      renames file with new_name
      updates file path and file_name with adjusted normalized_new_name for file_id in database
      MUST!!!! search all files for calls to this file. MUST DO SO CAREFULLy so that we aren't searching for a string that could potentially have differences. fileName.py replaced with fileName-ID312.py for example. It's possibe that we need to search for fileName (imports) but CAREFUL not to match fileNameTwo and end up with fileName-ID312Two. This MUST be avoided. So we should be careful and thorough with this search replace code. We must be sure to exclude anything outside of src as well. We do not want to be searching dependency files/folders etc. This could cause freezing and/or extreme time while the code gets stuck in some extensive, unnecessary search.

HELPER is_sub_helper=true
update_file_timestamp(file_id) this is primarily for function updates. If a function is updated, the file last updated timestamp should be updated. checksum gets updates (since this call is automated after every function update). No need for a separate call by AI. 

TOOLS
get_file(file_id)
update_file(file_id, new_path(*Can Be Null), language(*Can Be Null))
   Code should allow path change, but NOT file name change.
   File name changes must be done with rename_file(file_id, new_name)

HELPER is_sub_helper=false
rename_file(file_id, new_name)

update_file_by_path(old_path, new_path(*Can Be Null), language(*Can Be Null))code should allow path change, but NOT file name change. This must be done with rename_file(file_id, new_name)
return_statements should include "verify flows are added, if necessary, for this file in file_flows table"

File should have a has_changed function. Simply return true or false. 

TOOL
file_has_changed(file_id) creates checksum of file, then evaluates against current checksum in db. returns true/false

For all tables since we have both created at and updated at, we should have a check for setters and automatically add updated at if exists, automatically add created at if not exists and ignore the other in both cases (if create then ignore update, if update then ignore create). AI should not have to worry about created at, updated at, checksums. These should be automated. 

HELPER is_sub_helper=false
get_function(function_id)
get_function_by_name(function_name)

We have get_function_by_name but we should also have a get_function(id) that can be used for a quicker query by index id, if needed this will be used probably internally. If not needed now, it's handy to have already for any potential use case in the future or if AI has the ID but lost context or never had context regarding function entry table. Potentially a getter of a list of function ID's or some reference to function by ID and need to retrieve the rest of the function db data.

FUNCTION NAMES UNIQUE!!!!
Since this is FP, we do not have classes and therefore, function names cannot be duplicate??????? This is language agnostic so we don't know what language the use will be using and therefore we can't assume that the language will allow overloading. We should either make the name unique in database table as flat or create a function sig with name and params and force the sig to be unique. What do you think is best? Is overloading absolutely necessary? Our get_function for instance. We could have overloading get_function(id), and get_function(name). Or we could have get_function(id(*Can Be Null), name(*Can Be Null)){if id and name are none, return error; one is required}. or we could just be very explicit like what we are doing with get_function_by_name(name) and get_function(function_id). So maybe we should make the function names unique. add function should throw errors when duplicate function names are used.

FUNCTION METADATA
Will add function ID to function name. so it's always readily available. could be placed in docstring, but trying to account for all language syntax becomes a problem.

HELPERS is_sub_helper=true
validate_function_name(function_name, function_id) checks if function name contains function ID and returns true or false and an object or dic with function_name parsed into parts (function_name->name, function_name->ID)
function_name_normalizer(function_name, function_id) simple function that appends the function id to function name (function_name_id32 ) we'll keep id lower case for function names to ensure cross compatibility with all languages. AI can name functions in whatever way it wants, but we'll append with _idXXXX lower case and underscore to ensure compatibility since we will be doing this with code and not AI.

   rename_function(function_id, new_name)
      if(empty(new_name)){
         return error("there was no name parameter passed or it was an empty string. This parameter must be populated");
      }
      $function_data = get_function(function_id) to get function file_id and function name
         if failure because function_id does not exist in database, return error explaining issue
      $file_data =  get_file($function_data->file_id) to get file path and file name

      $existing_name_validity = validate_function_name($function_data->name, $function_id);
      $new_name_validity = validate_function_name($new_name, $function_id);
      $normalized_new_name = function_name_normalizer($new_name_validity->name, $function_id);
      
      Note: $existing_name_validity->valid == true assumes that $existing_name_validity->ID is not null. If ID was emtpy or null or None, $existing_name_validity->valid would be false.

      if(validate_function_name->valid && validate_function_name->ID != $function_id){
         $notes = "For some reason the pre-existing function name (${function_data->name}) had an incorrect function ID (${existing_name_validity->ID}). The function ID is (${function_id}). The new name has been cleaned and normalized, but this discrepancy is worrisome and should be investigated. This message is from rename_function."; 
      }
 
      $file_path = $file_data->path, $existing_name = function_data->name, $normalized_new_name, $function_data->file_id, $function_id

      use $file_path and $file_data->name to get actual file
      if file not found  
      $err = "function name in database $existing_name with function table id $function_id, is listed in database with file id of $function_data->file_id. That file in the database has path $file_path abd file name $file_data->name, but the file was not found. This needs to be investigated and resolved."
      return error($err);

      get file and finds function. If function not found with $existing_name
      return error("The existing function name is $existing_name, but when searching the file $file_path + $file_data->name from file table in database with id $function_data->file_id which is assigned to this function in the database, the function was not found in the file. Please investigate and resolve this issue");

      if($existing_name == $normalized_new_name){
         return ("File and function exist. No changes to name, nothing to change.");
      }

      replace function string existing_name with new_name. This needs to be coded carefully.
      if existing function is parseValueForThing, or parse_value_for_thing or whatever, it's possible that string exists ParseValueForThing or parse_value_for_thing_by_name or something. Must run replacement carefully. All calls to this function should also be replaced. Must do a search for calls to this function programatically and replace all. CAREFULLY. no in-between string like variable parseValueForThingVar get's replaced with parseValueForThing_id32Var. Not good. Also, we must distiquish between a function and a variable if possible. If this is too complex programatically, then we can have AI handle this and add a directive. We'll provide the ID after adding to database and provide a return_statements with a list of added function names, their file paths, the function db entry id and the concat string for the function name (ie. _id32).
      

      updates the function name in the database with $normalized_new_name

      return;

HELPERS is_sub_helper=false
rename_function(function_id, new_name)

## adding functions
additional-helper-project.md:
"`add_function(name: str, signature: str, file_id: int, is_pure: bool = false, dependencies: list = None)`"
We do not have a signature field for functions. Necessary? Useful? Should we add to schema or remove from additional helpers?
We do not have an is_pure field in functions table. Why is this here? Is it in directives? Or did you make this up out of thin air last session? Is it useful and needed? We should discuss.
dependencies are in the interactions table. This function isn't correct at all. Needs to be rewritten and re-evaluated. If this is completely wrong, many others might also be completely wrong. All helper functions in all helper functions files need to be reviewed.

add_function should take name, file ID, purpose, parameters, returns? Should we add the function return values if exist? If so, then this should be a filed added to the functions table.
ID is known by AI because it was working on the file before the update tool call and id is stored in file header metadata on file create automatically. 

TOOLS
add_function(name, file_id, purpose, params, returns)
   rename_function(function_id, name) called
   update_file_timestamp(file_id) called

created at field given current timestamp
updated at filed not update.
TRIGGERS NEED TO BE SET FOR THESE SO WE DON"T HAVE TO MANAGE MANUALLY WITH EVERY FUNCTION CALL

return_statements should include "are there any interactoins with this function"

helper/tool return must include function table new entry id and a return_statements "Do any interactions need to be added for this new function? Does the file database entry need to be updated?".
These return notes should be added in as new filed in helper_functions table in MCP core database.
return_statements. String, text or json. Not sure. All tools will query their own function by name and get the return statement before returning values. Return statement will be appending to return from helper functions.

TOOL
delete_function(function_id, note_reason:text, note_severit:string, note_source:string "ai" or "user", note_type: "entry_deletion") must delete all types with function_id and if exists must delete all types_functions with function_id. must delete all interactions with function_id as source or target.

## Need to evaluate interactions table. How useful is it?

## updating functions
TOOL
update_function(function_id, purpose=None, parameters=None, returns=None)
we will manage updated_at timestamp if sqlite doesn't do this automatically. Check purpose, parameters and returns for None to identify whether those fields need to be updated. 

return_statements should include "are there any interactions with this function"

return data should include function ID and interaction data for that function. Use get_interactions and append to return data with a note "do interactions need updating?". AI will always get and read the return data, so if it includes the necessary data for potential chaining, AI doesn't have to execute additional commands which would be needed anyway. We can think ahead for this.

HELPER is_sub_helper=false
update_function_file_location(function_id, old_file_id, new_file_id) 
This will be a helper function, not a tool. available for use but file location parameter not included in standard update_function tool because it's seldom, if ever, to be changed. The file a function lives in, once set, should be pretty much static. But there are occasions where a function might need to be moved to another file (probably for organization purposes) and so we should have a helper function for this. Any three parameters not found in db, return error so AI knows it needs to check param values.
update_file_timestamp(file_id) called 

additional-helpers-project.md "#### `update_function_purity(function_name: str, is_pure: bool)`
**Purpose**: Mark function as pure/impure after FP compliance check.
**Returns**: `{"success": true, "function": "...", "is_pure": true}`
**Use Case**: FP directives update purity status"
We don't have a purity field in the functions table. Review directives to check for any mention of this. If doesn't exist, explain use. I think we can remove this and will need to check for other useless helpers that have no database or directive mention.

TOOL:
add_functions(file_id, [(name,purpose,params,returns),(name,purpose,params,returns)...])
update_file_timestamp(file_id) called with every add_functions using file id . For this function, it's possible that add_functions() is used as a one-shot, meaning that adding all functions done at once. File must already exist. If not exists return error informing AI that file must first be added to database.

TOOL:
update_functions_for_file(file_id,[(name, purpose=None, parameters=None, returns=None), (name, purpose=None, parameters=None, returns=None), ...])
We will NOT have a generic update_functions (no fil ID needed). This enforces that functions in mass can only be updated for ONE file at a time. This prevents potential errors in attempting to update multiple functions accross multiple files. AI can probably handle this just fine, but it's very error prone when doing that. So if many files were modified, it can call update_functions_for_file multiple times, once for each file. It's just safer.
update_file_timestamp(file_id) called


## types
linked_function_id INTEGER,                -- Optional: ADT associated with specific function
So why the single linked_function_id?
If your design is recording the origin or defining function of a type (not every function that can operate on it), then one function makes sense:
Example: linked_function_id points to the constructor, definition site, or type declaration function.
Otherwise, if you intend to model all operations a type supports, youâ€™d use a link table, e.g.:
CREATE TABLE types_functions (
    type_id INTEGER REFERENCES types(id),
    function_id INTEGER REFERENCES functions(id),
    role TEXT  -- e.g. 'constructor', 'method', 'operator', etc.
);

name TEXT NOT NULL UNIQUE,
definition_json TEXT NOT NULL, -- JSON schema for ADT (e.g., {"type": "enum", "variants": ["A", "B"]})
description TEXT,
linked_function_id INTEGER,                -- Optional: ADT associated with specific function

TOOLS:
add_type(name, definition_json, description) (links if we won't migrate to types_functions table)
add_types([(name, definition_json, description), (name, definition_json, description),... ])
update_type(name, definition_json:CanBeNull, description(*Can Be Null))
update_types([(name, definition_json(*Can Be Null), description(*Can Be Null)), (name, definition_json(*Can Be Null), description(*Can Be Null)), ...])

## types_functions
TOOLS
add_type_function(type_name, function_name, role)
add_type_function_by_id(type_id function_id, role)
add_types_functions([(type_name, function_name, role),(type_name, function_name, role)...])

get_type_function_by_id(id) is_sub_helper
get_type_functions_by_function(function_name)
get_type_functions_by_type(type_name)
get_type_functions_by_role(role_name)

update_type_function_role(type_name, function_name, role); updates only the role. No need to update other type_function entries. Instead, we can add a new and remove an old if necessary (remove tool is universal, takes table name and table entry id).

## interactions
Need to evaluate interactions table. How useful is it?

TOOLS
get_all_intereactions(limit=None, orderby=None), get_interactons_by_source(name, limit=None, orderby=None), get_interactions_by_target(name, limit=None, orderby=None), get_interactons_by_type(type, limit=None, orderby=None), get_interactions(source, target), get_interaction_by_name(name, limit=None, orderby=None)- gets all interactions where function name is source or target, get_interaction(id)
update_interaction(id, source=None, target=None, type=None, descripton=None). 
add_interaction(source, target, type, description)
add_interactions(aray of [(source, target, type, description),(source, target, type, description),...])

## file_flows
TOOLS
add_file_flows(file_id, flow_id)
   This calls update_file_metadata(id)
get_files_by_flow(flow_id)
get_flows_for_file(file_id) This returns array of flow ids, then loops through flow id's to get
NO update file_flows table. Just remove and add a new one with correct information.

HELPERS
get_all_file_flows()
delete_file_flows(file_flows_id)
calls update_file_metadata(file_id)

## themes
name description ai_generated BOOLEAN confidence_score REAL DEFAULT 0.0

TOOLS
add_theme(name, description, ai_generated, confidence_score)
get_theme(theme_id)
get_theme_by_name(theme_name)
get_all_themes()
update_theme(them_id, name(*Can Be Null), description(*Can Be Null), confidence_score(*Can Be Null)) theme_id and at least one other parameter required, else throw error "must have a value to change (name, description, confidence_score)"

HELPERS
get_themes_by_maker(who_generated) "ai" or "user"
get_themes_by_confidence(greater_than) score must be greater than or equal to value passed
get_theme_name_by_id(theme_id)

## flows
name description ai_generated BOOLEAN confidence_score REAL DEFAULT 0.0

TOOLS
add_flow(name, description, ai_generated, confidence_score)
get_flow(flow_id)
get_all_flows()
update_flow(flow_id, name(*Can Be Null), descripton(*Can Be Null), confidence_score(*Can Be Null)) flow_id and at least one other parameter required, else throw error "must have a value to change (name, description, confidence_score)"

HELPERS
get_flows_by_maker(who_generated) "ai" or "user"
get_flows_by_confidence(greater_than) score must be greater than or equal to value passed
get_flow_name_by_id(flow_id)
get_flow_names_by_ids(flow_ids:dict/array)

## completion_path
name order_index -- For explicit ordering (1, 2, 3...) status -- pending, in_progress, complete description

TOOLS


## milestones
completion_path_id name status description
milestones relate to a certain step in the completion path. There could be many milestones before a step in the completion path can be marked as completed and the next step began. 

TOOLS

## flow_themes
TOOLS
add_flow_themes(flow_id, theme_id)
get_flows_for_theme(theme_id)
get_themes_for_flow(flow_id)
NO update flow_themes table. Just remove and add a new one with correct information.

HELPER
get_all_flow_themes()

## tasks, subtasks, sidequests and items. 
These all have to do with project progress tracking.
subtasks are children to tasks so the milestone is inherited from parent task. sidequest is immediate need issues and is not necessarily related to milestone/task/subtask. It may fall under these but it's more a "there is a problem and we need to pause everything and fix this" or "we need to make adjustments and these adjustments (dependencies, organization, clarifications, issues, etc.) must be completed before continuing with reglar work.". So it should be treated in this manner. Should have a get tasks by count, date as well. Get 3 latest tasks for instance. Should have an option in that actually for status. get 3 latest tasks complete. get all tasks incomplete (0 or -1 value for count). or unset, get 3 latest tasks (any status). Should exted this tool with a parameter of type for task, subtask or sidequest. As all should have these/this tool.

tasks have a flow_ids json table for related flows. We shouldn't have the need for getting tasks by flow as a general rule. tasks should be usually linear. Usually about one task at a time. Once items are complete, task is marked as complete and no real need for accessing that task in the future apart from general review for potential historical reference. But for task context, flows will be useful and therefore the flow_ids fields lists them. Should have a tool to update task flows and get task flows. These are separate from the general get tasks tool as they may probably be used more often. Subtasks inherit task flow(s). Sidequests are not necessarily flow specific. 

items are a series of task/subtask/sidequest items. The task/subtask/sidequest are high level descriptors of the set of "items" that must be accomplished. The items for that task/subtask/sidequest are created and must be fully completed before the task/subtask/sidequest can be marked as complete. This isn't a strict rule that should be forced however as a user can decide a task is complete and that certain items can be discarded. AI should discard accordingly, but this is normal user/AI interaction and doesn't need to be added to directives. We just don't want to make the directives too strict and so I'm clarifying my statemnt that "items.. must be fully complete before task/subtask/sidequest can be marked as complete" in order to show it as a generally obvious rule but not a strictly forced directive.

## Tasks
tasks linked to flows. flows linked to files. this relationship for tasks to files is sufficent as tasks are very temporary. Once done, they are only there for potential historical reference, nothing more. So getting flows for task, then get_files_by_flow(flow_id). Can loop through flows for all related files if necessary. 

TODO: code for loop above. code for getting status


## Subtasks

## Sidequests

## Items


## notes 
reference table reference id

## appropriate git getters and setters

