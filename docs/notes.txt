Read:
README.md
sys-prompt/aifp_system_prompt.txt
.aifp/ProjectBlueprint.md

docs/directives-project-updates-needed.md
docs/directive-review-master-checklist.md
docs/schema-updates-decisions.md
docs/directive-review-plan.md
docs/directive-json-schema-alignment-analysis.md

dev blueprints are in docs/blueprints/{}.md and the directive json files are located in docs/directives-json/{}, production directive md files located in src/aifp/reference/directives/{}.md. .aifp/ is our project management folder for dev, our project management/tracking database is there. We are following the FP coding style and managing the project through the project database in .aifp to ensure consistent and updated status. After every batch of completions, update the database to reflect the completed work.

src/aifp/database/schemas/user_preferences.sql
src/aifp/database/schemas/aifp_core.sql
src/aifp/database/schemas/project.sql
src/aifp/database/schemas/user_directives.sql
docs/sync-directives.py
docs/implementation-plans/phase-1-mcp-server-bootstrap.md
docs/implementation-plans/overview-all-phases.md

docs/helpers/helper-functions-reference.md

docs/db-schema/schemaExampleMCP.sql
docs/db-schema/schemaExampleProject.sql
docs/db-schema/schemaExampleSettings.sql
docs/db-schema/schemaExampleUserDirectives.sql
docs/blueprints/blueprint_system_prompt.md
docs/blueprints/blueprint_aifp_project_structure.md
docs/directives-markdown-reference.md

docs/directive-documentation-status.md
docs/directive-md-mapping.csv

Notes are md examples and init structuring are the idea evolution files
docs/directiveNotes/*
docs/initialStructuring/*

docs/directives-json/helpers_parsed.json
update with new helpers, fix paths (tools/ subdir and file names)

docs/directives-json/sync-directives.py
docs/helpers/helper-architecture.md
docs/helpers/generic-tools-project.md
docs/helpers/generic-tools-mcp.md

--help add_function, add_file, add_type.. etc. any that require reservation.

docs/directives-json/sync-directives.py
review available_helpers in directives json files. can remove completely? We must match helpers to directives in directive_helpers table. also directive_interactions and categories with directive_categories. All directive schema data should be available in directives json files as well as all interactions and helper function relationships.
docs/directive-json-schema-alignment-analysis.md
in this analysis, it's conforming to docs/directives-json/sync-directives.py. We can have a better structure for categories, etc. if needed, but I don't know if we need separate files for the linking/relationships. 

separate file for directive_interactions. This would have to be ran after directives entered to get directives by name, return id, so that entries into directive_interactions can happen using ID

separate file for helpers. Each helper json should have directives association by name(s). As a helper is entered into database, gets all listed directives from db by name, retrieves ID, adds directive_helpers relationship to database.

-- ===============================================================
-- Directive-Helper Mapping: Many-to-many relationship
-- ===============================================================

CREATE TABLE IF NOT EXISTS directive_helpers (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    directive_id INTEGER NOT NULL,
    helper_function_id INTEGER NOT NULL,
    execution_context TEXT,                  -- e.g., 'workflow_step_3', 'error_handler', 'validation'
    sequence_order INTEGER DEFAULT 0,        -- Order of execution if multiple helpers in workflow
    is_required BOOLEAN DEFAULT 1,           -- TRUE if helper must execute, FALSE if optional/conditional
    parameters_mapping JSON,                 -- Optional: maps directive workflow params to helper params
    description TEXT,                        -- Brief note on why this helper is used
    UNIQUE(directive_id, helper_function_id, execution_context),
    FOREIGN KEY (directive_id) REFERENCES directives(id) ON DELETE CASCADE,
    FOREIGN KEY (helper_function_id) REFERENCES helper_functions(id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS idx_directive_helpers_directive ON directive_helpers (directive_id);
CREATE INDEX IF NOT EXISTS idx_directive_helpers_helper ON directive_helpers (helper_function_id);


So with this flow, directives don't need to list helper functions. AI should have only a reference to helpers and can use the helpers/tools:
docs/helpers/info-helpers-core.txt :
get_helpers_for_directive(directive_id, include_helpers_data=false)
   include_helpers_data=false return all directive_helpers data for matches
   include_helpers_data=true calls get_helpers_by_id(helper_id array)
      returns all directive_helpers data AND helper_functions data for matches
get_directives_for_helper(helper_function_id, include_directives_data=false)
   include_directives_data=false return all directive_helpers data for matches
   include_directives_data=true calls get_directives(directive_id array)
      returns all directive_helpers data AND directives data for matches

need to flesh out return statements

must handle existing projects that are oop

Read:
README.md
sys-prompt/aifp_system_prompt.txt
.aifp/ProjectBlueprint.md

=======

our registry was created primarily from these:
docs/helpers/info-helpers-user-settings.txt
docs/helpers/info-helpers-project.txt
docs/helpers/info-helpers-core.txt
docs/helpers/info-helpers-user-custom.txt

docs/helpers/CONSOLIDATION_COMPLETE.md
docs/aifp-oop-policy.md
docs/helpers/IMPLEMENTATION_LOG.md

consolidated helpers:
docs/helpers/helpers-consolidated-git.md
docs/helpers/helpers-consolidated-index.md
docs/helpers/helpers-consolidated-orchestrators.md
docs/helpers/helpers-consolidated-core.md
docs/helpers/helpers-consolidated-project.md
docs/helpers/helpers-consolidated-settings.md
docs/helpers/helpers-consolidated-user-custom.md

directives next steps:
docs/directives-json/Tasks/DIRECTIVE_CLEANUP_TASK.md
docs/directives-json/Tasks/DIRECTIVES_QUICK_REF.md
docs/directives-json/Tasks/HELPER_FUNCTIONS_QUICK_REF.md
docs/directives-json/Tasks/MD_HELPER_REFS_ANALYSIS.md
docs/temp.txt
docs/directives-json/Tasks/MD_CLEANUP_CHECKLIST.md

docs/directives-json/Tasks/SQL_CLEANUP_NEEDED.md
docs/directives-json/DIRECTIVE_ARCHITECTURE.md

used_by_directive field in the helper json files needs to be evaluated when re-evaluating directives

src/aifp/reference/directives/user_preferences_update.md
new simpler template with no helper functions. system prompt tells AI to use get_helpers_for_directive(directive_id, include_helpers_data=true) so no need to add that even to the md files. Keep them clean with conceptual information not function calls.

 -- MD5/SHA256 checksum of ProjectBlueprint.md for sync validation
 file and blueprint file checksum removed from poject database. Should be no reason for it as we have git for historical reference. 

 intent_keywords_json removed from core replaced with directives_intent_keywords table
 have now intent_keywords table for separation similar to categories. 
 CHECK to ensure helper functions and directives json and md match new schema
docs/SCHEMA_NORMALIZATION_V1.9.md


for docs/directive-graph.txt please review. Should we incorporate this path system into our core database for AI clarity in directive usage? We have example helper functions but we don't need to implement those right away. We should first work with and assess the core project management system. Later we can reviwe our consolidated helpers and determine what we should add for any new tables and directive querying for AI we improved. 
This is very linear. I proposed a tree because it really does 
depend on what the current action is and what is needed next. So
 depending on current action, there may be choices instead of 
just one next action. Any table we create should have a many to 
many relationship so that when getting one directive, returned 
are a list of possible next steps. This can limit the "thinking"
 to a defined list and based on description and AI's current 
state in the project, AI can determine which to go to. But these
 should all have a loop back as well. An end point doesn't mean 
stop work, it means: is completion path, current path complete? 
If so, move to next completion path, move to first milestone, 
create first task. If not, check for open milestone. If no oopen
 milestone, move to next pending milestone, create first task 
for milestone. If open milestone, check for open task. If no 
open task, create next task. If open task, check for open task 
items. If no open task items, should task be marked complete? 
Should new task items be created (all task items should be 
created as soon as task is created, is something wrong?)? If new
 task, create task items. If open task items, work on next task 
item. file creations/updates function creations/updates, etc. 
etc. Loop back when anything is marked complete. This is the 
standard project management that really needs to be mapped out 
well. I believe we have directives for all of these so a map or 
tree of following the directives in this type of order should be
 quickly and easliy available.\
\
  -- Starting point
  INSERT INTO directive_flow (from_directive, to_directive, 
flow_type, priority, description)
  VALUES ('aifp_run', 'project_init', 'canonical', 100, 'First 
directive on initial run');

  -- After project init
  INSERT INTO directive_flow (from_directive, to_directive, 
flow_type, priority, condition_description)
  VALUES ('project_init', 'blueprint_read', 'canonical', 100, 
'Read ProjectBlueprint.md');\
\
In your examples here, project init is next step, but if project
 is initialized, is there an automatic jump to blueprint_read? \
\
aifp_run should actually first strat with aifp_status. Status 
should accurately get current state programmatically for AI to 
process and determine what to do (init, continue working, etc.).
 We could potentially offer starting points based on the 
returned value (if not initialized, suggest init. If in 
progress, suggest continuation directive(s)).\
\
status should query the database using all of the helpers and 
potentially some custom queries as well, getting if user_custom 
exists, if project initialized (db's in place, blueprint in 
place, infrastructure in place, etc), get themes and determing 
point in completion path. Determine current milestone and task. 
Determine task/subtask/sidequest state and item state relative 
to any of those. Get last X number of completed items for 
context. If X not available, get previous task/subtask/sidequest
 and last X number of completed items for context. Get current 
incomplete item and next item for context. All should be 
returned as a comprehensive current state, to include 
infrastructure guidance, project blueprint location for AI read,
 etc. \
\
From status state some starting point suggestions can be offered
 and AI can determine how to proceed. 