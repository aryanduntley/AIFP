Read:
README.md
sys-prompt/aifp_system_prompt.txt
src/aifp/reference/guides/supportive_context.txt
.aifp/ProjectBlueprint.md

directives json are in docs/directives-json/
directives md are in src/aifp/resource/directives/
helpers json is in docs/helpers/json/
Everything above src/aifp/ is dev.
helpers are in docs/json/helpers/
directive flows are in docs/directives-json/directive_flow_(project,user-preferences,fp).json
helper functions are AI tools for  repeated operations. State DB creation for example is one-time during init, so it's internal to aifp_init code, not a helper.  

src/aifp/database/schemas/user_directives.sql
src/aifp/database/schemas/aifp_core.sql
src/aifp/database/schemas/project.sql
src/aifp/database/schemas/user_preferences.sql

docs/proposals/use-case-2-routing-fix.md

system prompt:
 **is_new_session=true**: First interaction, after breaks, user asks status
 not when user asks status. Is new is only new session when no context exists. Use get_project_status instead. Should return the same general information. Must add supportive context to get_project_status

Do not read or modify notes.txt. That is just for me.                         

return statements for aifp_init

think out useful return values for certain helper functions, like generic getter/setters should return schema, possibly some helper or directive references useful or relative to current function call and database.

when coding helpers, if case 2, ensure we make a return value that indicates to AI case 2 active. Probably during status call(s)

MUST make OOP wrapper examples

--help add_function, add_file, add_type.. etc. any that require reservation.

docs/directives-json/sync-directives.py

Use Case 2, need very expliting paths to use case 2 directives when found that use case 2 exists. AI should be FORCED to read those directives at new session when valid.

next: import json to db. re-create project db if needed. Begin populating project db with mcp codebase we have now. after done, prep for full mcp implementation. Helpers is_tool=true to be made as actual mcp tools. 

=============================
Token cost: ~15-20k tokens loaded on every API call. Fora tool that's meant to be cost-conscious (all trackingoff by default), the system prompt itself is the largestfixed cost per interaction.

Diminishing returns: Studies on long system promptssuggest instruction-following degrades past a certainlength. Rules at the end get less attention than rules at the top. The current structure front-loads the criticalstuff (proactive behavior, aifp_run, FP baseline) whichis good, but the behavioral rules at line ~500+ are inthe weaker zone.

Possible optimizations (not urgent, but worth considering later):- The FP coding style section (~lines 110-290) is verydetailed with code examples. Some of that could move tothe FP directive MD files and be referenced rather thaninlined — the AI already has access to those viaget_directive_content().- The Use Case 2 explanation (~lines 525-545) could beshortened since it's also thoroughly covered indirectives.- The DRY principle section with code examples is quitelong for a system prompt rule.

For now at ~650 lines with the additions, it's fine. Ifit grows further, I'd look at extracting the detailed FPcode examples into directive references and keeping onlythe rules in the prompt.    
=============================

Confidence: High for active behavior, moderate for full directive compliance. Here's my honest breakdown: What will work well The system prompt is strong. It's unambiguous about proactive behavior — "Call aifp_run FIRST", "DO NOT wait", "act based on project state." AI models follow system prompts reliably, especially when instructions are this direct. The aifp_run on every interaction pattern will keep the MCP server "alive" as you intended. The session bundle is well-designed. Giving AI everything upfront (status, settings, directive names, FP index) means it doesn't have to figure out what to query. That reduces the chance of it going passive. Reserve→write→finalize is now explicit. With mandatory flags in the workflow, AI won't skip these steps. Where I'd have concerns Directive depth. AI will follow the top-level flow (run → status → init/continue) reliably. But the deeper directive chains (file_write triggers reserve_finalize, which triggers update_db, which checks interactions) — the further down the chain, the more likely AI drops steps or shortcuts. The return_statements on helpers will help here, as they tell AI "you're not done yet, do X next." Context window pressure. The session bundle is ~15-20k tokens. Add the system prompt, conversation history, and code context — on long sessions, older directive context gets compressed or evicted. That's when AI starts "forgetting" to call helpers or skipping finalization steps. The aifp_run(is_new_session=false) lightweight reminder on every interaction mitigates this, but doesn't eliminate it. Novel situations. The directive flows cover the happy path well. When something unexpected happens (partial write failure, user changes mind mid-task, edge cases), AI will fall back to its own judgment rather than consulting directives. That's fine for capable models but less predictable. What would increase confidence 1. Testing with real sessions — the biggest unknown is how a specific AI client (Claude Desktop, Cursor, etc.) handles MCP tool calls in practice. Some clients throttle tool calls or have their own system prompts that compete with yours. 2. The return_statements pattern is your best lever. Every helper that returns data with "AI should do X next" guidance keeps the chain going. You've done this well in the orchestrators. Make sure it carries through to all helpers during MCP implementation. 3. The aifp_run on every interaction is the key insurance policy. Even if AI drifts, it gets pulled back every message. That's a good design. Bottom line: a capable model (Claude, GPT-4 class) will follow this system actively, not sit idle. The risk isn't passivity — it's depth of compliance on multi-step chains during long sessions.

23.30
=============================
docs/HELPER_IMPLEMENTATION_PLAN.md
docs/ORCHESTRATOR_IMPLEMENTATION_PLAN.md
docs/DIRECTIVE_ADDITIONS_IMPLEMENTATION_PLAN.md
docs/WATCHDOG_IMPLEMENTATION_PLAN.md

docs/directives-json/IMPORT_REPORT_2026-01-10.md

docs/HELPER_AUDIT_REPORT.md
docs/helpers/json/PARAMETER_COMPLETION_PROGRESS.md

docs/helpers/REMOVE-helpers-consolidated.md
docs/helpers/CONSOLIDATION_COMPLETE.md
docs/directives-json/Tasks/HELPER_FUNCTIONS_MAPPING_PROGRESS.md
docs/helpers/JSON_HELPERS_CONSOLIDATION_ISSUE.md

docs/directives-json/DIRECTIVE_ARCHITECTURE.md
docs/HELPER_IMPORT_ANALYSIS_2025-12-16.md
docs/DIRECTIVE_JSON_CLEANUP_REPORT_2025-12-16.md
docs/HELPER_IMPORT_ANALYSIS_2025-12-16.md\ 

Here are our contextual files for the mapping work:
docs/helpers/json/README.md
docs/MAPPING_SETUP_COMPLETE.md
docs/directives-json/Tasks/DIRECTIVES_MAPPING_PROGRESS.md
docs/directives-json/Tasks/HELPER_FUNCTIONS_MAPPING_PROGRESS.md
docs/DIRECTIVE_NAVIGATION_SYSTEM.md

docs/DIRECTIVE_WORKFLOW_PATH.md
docs/DIRECTIVE_HELPER_MAPPING_IMPLEMENTATION_PLAN.md
docs/DIRECTIVE_FLOW_GAP_ANALYSIS.md

docs/HELPER_MAPPING_ANALYSIS.md
docs/PHASE_8_HELPER_MAPPING_STRATEGY.md

docs/UNMAPPED_HELPERS_ANALYSIS.md
docs/HELPER_AUDIT_REPORT.md

docs/PHASE_1_COMPLETE.md

docs/helpers/info-helpers-user-settings.txt
docs/helpers/info-helpers-core.txt
docs/helpers/info-helpers-project.txt
docs/helpers/info-helpers-user-custom.txt

src/aifp/database/schemas/user_preferences.sql
src/aifp/database/schemas/aifp_core.sql
src/aifp/database/schemas/project.sql
src/aifp/database/schemas/user_directives.sql
docs/sync-directives.py
docs/implementation-plans/phase-1-mcp-server-bootstrap.md
docs/implementation-plans/overview-all-phases.md
